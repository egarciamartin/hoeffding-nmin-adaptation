\section{vfbn2 File Reference}
\label{vfbn2}\index{vfbn2@{vfbn2}}


\subsection{Detailed Description}
Learns the structure of a Belief\-Net from a very large data set using sampling and a new search proceedure. 

Learns the structure and parameters of a Bayesian network, accelerated with sampling as described in {\tt this paper}. All variables must be categorical. vfbn2 searches for high scoring Bayesian network structures by considering adding and removing every possible edge (but not reversing as traditional methods do), making the one that has highest score on training data, and repeating until no change improves the score. Unlike other learners, vfbn2 uses statistical tests and only uses enough data to be sure that it knows which change is best with high confidence (see the -delta parameter below). This allows vfbn2 to be much faster than traditional methods when there is enough data to make good decisions. It also allows it to learn from data streams (see the -stdin flag below). vfbn2 also differs from traditional Bayesian network learners by running the search for the model at each variable in parallel. Whenever the statistical tests at one node indicate that a change should be made it is made, and this fact is broadcast to the searches at the other nodes which immediately stop considering any changes that would add a cycle to the network given the change just made.

vfbn2 takes input and does output in {\tt c4.5 format}. It expects to find the files {\tt $<$stem$>$.names} and {\tt $<$stem$>$.data}.

\begin{Desc}
\item[{\bf Wish List}]An API to this learner like the one to learning Belief\-Net structure in beliefnet-engine.h \end{Desc}
\subsubsection*{Arguments}

\begin{itemize}
\item -f 'filestem'\begin{itemize}
\item Set the name of the dataset (default DF)\end{itemize}
\item -source 'dir'\begin{itemize}
\item Set the source data directory (default '.')\end{itemize}
\item -start\-From 'filename'\begin{itemize}
\item Use net in 'filename' as starting point, must be BIF file (default start from empty net)\end{itemize}
\item -output\-To 'filename'\begin{itemize}
\item Output the learned net to 'filename' in BIF format.\end{itemize}
\item -delta 'prob'\begin{itemize}
\item Allowed chance of error in each decision (default 0.0000000001 that's .00000001 percent)\end{itemize}
\item -tau 'tie error'\begin{itemize}
\item Call a tie when score might change less than tau percent (default 0.001)\end{itemize}
\item -chunk 'count'\begin{itemize}
\item Accumulate 'count' examples before testing for a winning search step(default 10000)\end{itemize}
\item -no\-Remove\begin{itemize}
\item VFBN2 won't consider removing links (default remove)\end{itemize}
\item -in\-Step\begin{itemize}
\item VFBN2 won't let any search make a second step before everyone makes a step (default no restriction)\end{itemize}
\item -limit\-Megs 'count'\begin{itemize}
\item Limit dynamic memory allocation to 'count' megabytes networks that are too large will not be considered (default no limit)\end{itemize}
\item -limit\-Minutes 'count'\begin{itemize}
\item Limit the run to 'count' minutes then return current model (default no limit)\end{itemize}
\item -stdin\begin{itemize}
\item Reads training examples from stdin instead of from 'stem'.data causes a 2 second delay to help give data generation time to setup (default off) -seed 's'\item Seed for random numbers (default random)\end{itemize}
\item -max\-Parents\-Per\-Node 'num'\begin{itemize}
\item Limit each node to 'num' parents (default no max).\end{itemize}
\item -max\-Parameter\-Count 'count'\begin{itemize}
\item Limit net to 'count' parameters (default no max).\end{itemize}
\item -v\begin{itemize}
\item Can be used multiple times to increase the debugging output\end{itemize}
\item -h\begin{itemize}
\item Run vfbn2 -h for a list of the arguments and their meanings.\end{itemize}
\end{itemize}


