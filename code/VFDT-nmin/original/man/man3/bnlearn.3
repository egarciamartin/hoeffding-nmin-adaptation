.TH "bnlearn" 3 "28 Jul 2003" "VFML" \" -*- nroff -*-
.ad l
.nh
.SH NAME
bnlearn \- 
.SH "Detailed Description"
.PP 
Learns the structure of a BeliefNet from a data set. Designed to be easily modified. 

Learns the structure and parameters of a Bayesian network using the standard method. The structural prior is set by using P(S) = kappa ^ (symetric difference between the net and the prior net). The parameter prior is K2. This is basically a wrapper around the code in bnlearn-engine.h. This program is a stripped down version of the vfbn learner, done so that the code would be clearer and easier to modify.
.PP
bnlearn can load training data into RAM, if space is available, or it can scan data repeatedly from disk.
.PP
See the documentation for the bnlearn-engine for even more information about the parameters and their meanings.
.PP
bnlearn takes input and does output in \fCc4.5 format\fP. It expects to find the files \fC<stem>.names\fP and \fC<stem>.data\fP.
.PP
\fBThanks\fP
.RS 4
to Matthew Richardson for making substantial optimizations to the bnlearn program. 
.RE
.PP
.PP
\fBWish List\fP
.RS 4
A version of this program that is intelligent about dealing with unobserved (or partially observed) variables. 
.RE
.PP
.SS "Arguments"
.PP
.IP "\(bu" 2
-f 'filestem'
.IP "  \(bu" 4
Set the name of the dataset (default DF)
.PP

.IP "\(bu" 2
-source 'dir'
.IP "  \(bu" 4
Set the source data directory (default '.')
.PP

.IP "\(bu" 2
-startFrom 'filename'
.IP "  \(bu" 4
Use net in filename as starting point, must be BIF file (default start from empty net)
.PP

.IP "\(bu" 2
-outputTo 'filename'
.IP "  \(bu" 4
Output the learned net to filename
.PP

.IP "\(bu" 2
-limitMegs 'count'
.IP "  \(bu" 4
Limit dynamic memory allocation to 'count' megabytes, don't consider networks that take too much space (default no limit)
.PP

.IP "\(bu" 2
-limitMinutes 'count'
.IP "  \(bu" 4
Limit the run to 'count' minutes then return current model (default no limit)
.PP

.IP "\(bu" 2
-noCacheTrainSet
.IP "  \(bu" 4
Repeatedly read training data from disk and do not cache it in RAM (default read data into RAM at beginning of run)
.PP

.IP "\(bu" 2
-stdin
.IP "  \(bu" 4
Reads training examples from stdin instead of from stem.data causes a 2 second delay to help give input time to setup (default off, not compatable with -noCacheTrainSet)
.PP

.IP "\(bu" 2
-noReverse
.IP "  \(bu" 4
Doesn't reverse links to make nets for next search step (default reverse links)
.PP

.IP "\(bu" 2
-parametersOnly
.IP "  \(bu" 4
Only estimate parameters for current structure, no other learning
.PP

.IP "\(bu" 2
-seed 's'
.IP "  \(bu" 4
Seed for random numbers (default random)
.PP

.IP "\(bu" 2
-maxSearchSteps 'num'
.IP "  \(bu" 4
Limit to 'num' search steps (default no max).
.PP

.IP "\(bu" 2
-maxParentsPerNode 'num'
.IP "  \(bu" 4
Limit each node to 'num' parents (default no max).
.PP

.IP "\(bu" 2
-maxParameterGrowthMult 'mult'
.IP "  \(bu" 4
Limit net to 'mult' times starting # of parameters (default no max).
.PP

.IP "\(bu" 2
-maxParameterCount 'count'
.IP "  \(bu" 4
Limit net to 'count' parameters (default no max).
.PP

.IP "\(bu" 2
-kappa 'kappa'
.IP "  \(bu" 4
The structure prior penalty for batch (0 - 1), 1 is no penalty (default 0.5)
.PP

.IP "\(bu" 2
-v
.IP "  \(bu" 4
Can be used multiple times to increase the debugging output
.PP

.IP "\(bu" 2
-h
.IP "  \(bu" 4
Run bnlearn -h for a list of the arguments and their meanings.
.PP

.PP

.PP
.SH SYNOPSIS
.br
.PP
.SH "Author"
.PP 
Generated automatically by Doxygen for VFML from the source code.
